{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd92b037-cf23-4f09-9049-bbcbbc4ec871",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3823421614.py, line 36)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 36\u001b[1;36m\u001b[0m\n\u001b[1;33m    Exploratory Data Analysis (EDA)\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load datasets\n",
    "train_path = \"train.csv\"  # Update path if needed\n",
    "test_path = \"test.csv\"\n",
    "submission_path = \"sample_submission.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "# Display first few rows\n",
    "print(\"Train Data Preview:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nTest Data Preview:\")\n",
    "print(test_df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values in Train Data:\")\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing Values in Test Data:\")\n",
    "print(test_df.isnull().sum())\n",
    "\n",
    "# Handle missing values in 'winddirection' (test dataset) - FIXED METHOD\n",
    "most_frequent_winddir = test_df['winddirection'].mode()[0]\n",
    "test_df.loc[:, 'winddirection'] = test_df['winddirection'].fillna(most_frequent_winddir)\n",
    "\n",
    "# Verify that missing values are handled\n",
    "print(\"\\nMissing Values After Handling:\")\n",
    "print(test_df.isnull().sum())\n",
    "\n",
    "# ==============================\n",
    "# Exploratory Data Analysis (EDA)\n",
    "# ==============================\n",
    "\n",
    "# Distribution of the Target Variable (Rainfall) - FIXED WARNING\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='rainfall', data=train_df, hue='rainfall', palette=\"viridis\", legend=False)\n",
    "plt.title(\"Distribution of Rainfall (Target Variable)\")\n",
    "plt.xlabel(\"Rainfall (0 = No, 1 = Yes)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# Check Correlations Between Features\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(train_df.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "# Boxplot to Identify Outliers in Key Features\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=train_df[['pressure', 'maxtemp', 'mintemp', 'humidity', 'windspeed']])\n",
    "plt.title(\"Boxplot of Key Features\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Data Preprocessing & EDA Completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b3d9e39-41c9-46b3-9669-fcf5c8808b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Outliers handled successfully!\n"
     ]
    }
   ],
   "source": [
    "# Function to remove outliers using Interquartile Range (IQR)\n",
    "def remove_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Remove outliers from key features\n",
    "for col in ['pressure', 'humidity', 'windspeed']:\n",
    "    train_df = remove_outliers(train_df, col)\n",
    "\n",
    "print(\"Outliers handled successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f109290c-9057-457e-abc7-4aead85d968e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature selection completed!\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "train_df.drop(columns=['id', 'day', 'temparature', 'mintemp', 'dewpoint'], inplace=True)\n",
    "test_df.drop(columns=['id', 'day', 'temparature', 'mintemp', 'dewpoint'], inplace=True)\n",
    "\n",
    "print(\"Feature selection completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8bb0e04-7189-4583-a58e-6e230025368f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Train-Test Split Completed!\n",
      "Training samples: 1704\n",
      "Validation samples: 427\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "X = train_df.drop(columns=['rainfall'])\n",
    "y = train_df['rainfall']\n",
    "\n",
    "# Split into train (80%) and validation (20%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Train-Test Split Completed!\")\n",
    "print(\"Training samples:\", X_train.shape[0])\n",
    "print(\"Validation samples:\", X_val.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfe1a13a-90e4-41a4-97d1-5c96bde064fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8758782201405152\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.63      0.69        93\n",
      "           1       0.90      0.94      0.92       334\n",
      "\n",
      "    accuracy                           0.88       427\n",
      "   macro avg       0.83      0.79      0.81       427\n",
      "weighted avg       0.87      0.88      0.87       427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on Validation Set\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Evaluate Performance\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "976e5778-c837-486f-b46e-70569dcf06b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores (After Scaling): [0.87390029 0.87096774 0.85630499 0.82404692 0.87352941]\n",
      "Mean Accuracy (After Scaling): 0.8597498706227359\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Apply the same transformation to test data\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Train Logistic Regression on scaled data\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Perform Cross-Validation with Scaled Data\n",
    "cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(\"Cross-Validation Scores (After Scaling):\", cv_scores)\n",
    "print(\"Mean Accuracy (After Scaling):\", cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "156d5962-ddd9-4f29-b9df-9b2c98078c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Submission file created successfully!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Ensure test_df has the same feature columns as X_train\n",
    "test_features = X_train.columns  # Get the correct feature names used in training\n",
    "test_df = test_df[test_features]  # Select only these columns\n",
    "\n",
    "# Re-scale test data using the same scaler fitted on training data\n",
    "test_scaled = scaler.transform(test_df)\n",
    "\n",
    "# Predict rainfall on the test dataset\n",
    "test_df['rainfall'] = model.predict(test_scaled)\n",
    "\n",
    "# Restore `id` column before saving (if it was dropped)\n",
    "original_test_df = pd.read_csv(\"test.csv\")  # Reload the original file\n",
    "test_df['id'] = original_test_df['id']\n",
    "\n",
    "# Save submission file\n",
    "test_df[['id', 'rainfall']].to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\" Submission file created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e04cd7-fa75-4297-afd3-bcaab73d6a60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
